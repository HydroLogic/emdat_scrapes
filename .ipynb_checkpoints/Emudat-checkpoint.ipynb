{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping EMUDAT: A First Attempt\n",
    "This is my attempt to scrape the very detailed disaster database hosted by EMUDAT [link here](http://www.emdat.be/disaster_list/index.html). [Fabio](http://fabio-lana.blogspot.it/) inspired this, and a big shout out to Stevie B. I will be breaking this tutorial up into equal parts code and equal parts research.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intoduction\n",
    "\n",
    "Risk is calculated by the following equation: [1][ref1]\n",
    "        \n",
    "$$RS = PT * PL * V * A$$\n",
    "\n",
    "Where\n",
    "+ **PT** is the temporal (e.g. annual) probability of occurrence of a specific hazard scenario (Hs) with a given return period in an area\n",
    "+ **PL** is the locational or spatial probability of occurrence of a specific hazard scenario with a given return period in an area affecting the elements-at-risk\n",
    "+ **V** is the physical vulnerability, specified as the degree of damage to a specific element-at-risk Es given the local intensity caused due to the occurrence of hazard scenario Hs\n",
    "+ **A** is the quantification (value) of the specific type of element at risk evaluated. If the value is expressed in monetary terms, the risk may also be expressed as potential damage.\n",
    "\n",
    "$$E=f(F,L,T)$$\n",
    "\n",
    "Where \n",
    "+ **E** is the nature/extent of effects,\n",
    "+ **F** is the flood characteristics (extents, depth, velocity, etc…),\n",
    "+ **L** is the location characteristics (inside/outside buildings, nature of housing, etc...)\n",
    "+ **P** is the population characteristics (age, health, GDP, income, gender, etc…)\n",
    "*The **F** in this case represents the distribution both spatially and temporally. Fabio has a good representation of the different aspects of this in the following image:*\n",
    "\n",
    "![risk framework](http://1.bp.blogspot.com/-RaW18RN6ZIU/Va313WJ2WeI/AAAAAAAABfM/AiiEa3UOihU/s640/image049.png)\n",
    "\n",
    "Hazards in general can be defined by their liklihood of occurance (temporal probability) within a certain area (spatial probability).\n",
    "\n",
    "Fabio breaks the flood hazard component into two main layers:\n",
    "**Expected Impact Value (EIV)** is based off the probability of a hazard happening on a monthly basis and the amount of people affected by the hazard.\n",
    ">A simple SPARC example, if a pixel has a 0.1 chance of being flooded in any given March, and an estimated areas risk population (ARP) of 1000, its March EIV is 100.\n",
    "\n",
    ">It is also known, that the most accurate estimates on damages and people at risk are achieved when the number of return periods are located in the lower tail of the risk curve, while adding an extra return period in the upper tail has very little influence on the final risk estimate. [2][ref1]\n",
    "\n",
    "He also uses the distribution of rainfall throughout the months in order to calculate against the ARP becasue of the correlation between rainfall and flooding events. He lists below some of the key characteristics involed in the analysis. The background paper prepared for the Global Assessment Report on Disaster Risk Reduction 2013 lists the following data:\n",
    "\n",
    "+ **Hydromorphometric:**\n",
    "    + Drainage area\n",
    "    + Mean basin elevation\n",
    "    + Mean basin slope\n",
    "    + Basin shape\n",
    "    + Main channel length\n",
    "    + Main channel slope\n",
    "    + Drainage frequency\n",
    "    + Distance to final outlet\n",
    "+ **Land cover:**\n",
    "    + Surface water storage\n",
    "    + Forest cover\n",
    "    + Impervious cover\n",
    "+ **Climatic time-series:**\n",
    "    + Mean annual precipitation\n",
    "    + Temporal mean of monthly maximum precipitation\n",
    "    + Minimum mean monthly temperature\n",
    "+ **Climatic zones:**\n",
    "    + Percentage area of Köppen-Geiger climatic zones\n",
    "+ **Upstream dam network:**\n",
    "    + Dam characteristics\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### “Source-Pathway-Receptor-Consequence\" Model\n",
    "\n",
    "![pic](http://2.bp.blogspot.com/-SvZl09V9OEM/Va31tru8DrI/AAAAAAAABfM/z28qIqmzqT4/s1600/image012.jpg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os, json, sys, string, io\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib2\n",
    "import pycountry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scripts import scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cc = scrape.iso3dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with ISO3:DZA\n",
      "Done with ISO3:AGO\n",
      "Done with ISO3:EGY\n",
      "Done with ISO3:BGD\n",
      "Done with ISO3:NER\n",
      "Done with ISO3:LIE\n",
      "Done with ISO3:NAM\n",
      "Done with ISO3:BGR\n",
      "Done with ISO3:BOL\n",
      "Done with ISO3:GHA\n",
      "Done with ISO3:CCK\n",
      "Done with ISO3:PAK\n",
      "Done with ISO3:CPV\n",
      "Done with ISO3:JOR\n",
      "Done with ISO3:LBR\n",
      "Done with ISO3:LBY\n",
      "Done with ISO3:MYS\n",
      "Done with ISO3:IOT\n",
      "Done with ISO3:PRI\n",
      "Done with ISO3:MYT\n",
      "Done with ISO3:PRK\n",
      "Done with ISO3:PSE\n",
      "Done with ISO3:TZA\n",
      "Done with ISO3:BWA\n",
      "Done with ISO3:KHM\n",
      "Done with ISO3:UMI\n",
      "Done with ISO3:TTO\n",
      "Done with ISO3:PRY\n",
      "Done with ISO3:HKG\n",
      "Done with ISO3:SAU\n",
      "Done with ISO3:LBN\n",
      "Done with ISO3:SVN\n",
      "Done with ISO3:BFA\n",
      "Done with ISO3:SVK\n",
      "Done with ISO3:MRT\n",
      "Done with ISO3:HRV\n",
      "Done with ISO3:CHL\n",
      "Done with ISO3:CHN\n",
      "Done with ISO3:KNA\n",
      "Done with ISO3:JAM\n",
      "Done with ISO3:SMR\n",
      "Done with ISO3:GIB\n",
      "Done with ISO3:DJI\n",
      "Done with ISO3:GIN\n",
      "Done with ISO3:FIN\n",
      "Done with ISO3:URY\n",
      "Done with ISO3:VAT\n",
      "Done with ISO3:STP\n",
      "Done with ISO3:SYC\n",
      "Done with ISO3:NPL\n",
      "Done with ISO3:CXR\n",
      "Done with ISO3:LAO\n",
      "Done with ISO3:YEM\n",
      "Done with ISO3:BVT\n",
      "Done with ISO3:ZAF\n",
      "Done with ISO3:KIR\n",
      "Done with ISO3:PHL\n",
      "Done with ISO3:SXM\n",
      "Done with ISO3:ROU\n",
      "Done with ISO3:VIR\n",
      "Done with ISO3:SYR\n",
      "Done with ISO3:MAC\n",
      "Done with ISO3:NIC\n",
      "Done with ISO3:MLT\n",
      "Done with ISO3:KAZ\n",
      "Done with ISO3:TCA\n",
      "Done with ISO3:PYF\n",
      "Done with ISO3:NIU\n",
      "Done with ISO3:DMA\n",
      "Done with ISO3:GBR\n",
      "Done with ISO3:BEN\n",
      "Done with ISO3:GUF\n",
      "Done with ISO3:BEL\n",
      "Done with ISO3:MSR\n",
      "Done with ISO3:TGO\n",
      "Done with ISO3:DEU\n",
      "Done with ISO3:GUM\n",
      "Done with ISO3:LKA\n",
      "Done with ISO3:SSD\n",
      "Done with ISO3:FLK\n",
      "Done with ISO3:PCN\n",
      "Done with ISO3:BES\n",
      "Done with ISO3:GUY\n",
      "Done with ISO3:CRI\n",
      "Done with ISO3:COK\n",
      "Done with ISO3:MAR\n",
      "Done with ISO3:MNP\n",
      "Done with ISO3:LSO\n",
      "Done with ISO3:HUN\n",
      "Done with ISO3:TKM\n",
      "Done with ISO3:SUR\n",
      "Done with ISO3:NLD\n",
      "Done with ISO3:BMU\n",
      "Done with ISO3:HMD\n",
      "Done with ISO3:TCD\n",
      "Done with ISO3:GEO\n",
      "Done with ISO3:MNE\n",
      "Done with ISO3:MNG\n",
      "Done with ISO3:MHL\n",
      "Done with ISO3:MTQ\n",
      "Done with ISO3:BLZ\n",
      "Done with ISO3:NFK\n",
      "Done with ISO3:MMR\n",
      "Done with ISO3:AFG\n",
      "Done with ISO3:BDI\n",
      "Done with ISO3:VGB\n",
      "Done with ISO3:BLR\n",
      "Done with ISO3:BLM\n",
      "Done with ISO3:GRD\n",
      "Done with ISO3:TKL\n",
      "Done with ISO3:GRC\n",
      "Done with ISO3:GRL\n",
      "Done with ISO3:SHN\n",
      "Done with ISO3:AND\n",
      "Done with ISO3:MOZ\n",
      "Done with ISO3:TJK\n",
      "Done with ISO3:THA\n",
      "Done with ISO3:HTI\n",
      "Done with ISO3:MEX\n",
      "Done with ISO3:ZWE\n",
      "Done with ISO3:LCA\n",
      "Done with ISO3:IND\n",
      "Done with ISO3:LVA\n",
      "Done with ISO3:BTN\n",
      "Done with ISO3:VCT\n",
      "Done with ISO3:VNM\n",
      "Done with ISO3:NOR\n",
      "Done with ISO3:CZE\n",
      "Done with ISO3:ATF\n",
      "Done with ISO3:ATG\n",
      "Done with ISO3:FJI\n",
      "Done with ISO3:HND\n",
      "Done with ISO3:MUS\n",
      "Done with ISO3:DOM\n",
      "Done with ISO3:LUX\n",
      "Done with ISO3:ISR\n",
      "Done with ISO3:FSM\n",
      "Done with ISO3:PER\n",
      "Done with ISO3:REU\n",
      "Done with ISO3:IDN\n",
      "Done with ISO3:VUT\n",
      "Done with ISO3:MKD\n",
      "Done with ISO3:COD\n",
      "Done with ISO3:COG\n",
      "Done with ISO3:ISL\n",
      "Done with ISO3:GLP\n",
      "Done with ISO3:ETH\n",
      "Done with ISO3:COM\n",
      "Done with ISO3:COL\n",
      "Done with ISO3:NGA\n",
      "Done with ISO3:TLS\n",
      "Done with ISO3:TWN\n",
      "Done with ISO3:PRT\n",
      "Done with ISO3:MDA\n",
      "Done with ISO3:GGY\n",
      "Done with ISO3:MDG\n",
      "Done with ISO3:ATA\n",
      "Done with ISO3:ECU\n",
      "Done with ISO3:SEN\n",
      "Done with ISO3:ESH\n",
      "Done with ISO3:MDV\n",
      "Done with ISO3:ASM\n",
      "Done with ISO3:SPM\n",
      "Done with ISO3:CUW\n",
      "Done with ISO3:FRA\n",
      "Done with ISO3:LTU\n",
      "Done with ISO3:RWA\n",
      "Done with ISO3:ZMB\n",
      "Done with ISO3:GMB\n",
      "Done with ISO3:WLF\n",
      "Done with ISO3:JEY\n",
      "Done with ISO3:FRO\n",
      "Done with ISO3:GTM\n",
      "Done with ISO3:DNK\n",
      "Done with ISO3:IMN\n",
      "Done with ISO3:MAF\n",
      "Done with ISO3:AUS\n",
      "Done with ISO3:AUT\n",
      "Done with ISO3:SJM\n",
      "Done with ISO3:VEN\n",
      "Done with ISO3:PLW\n",
      "Done with ISO3:KEN\n",
      "Done with ISO3:TUR\n",
      "Done with ISO3:ALB\n",
      "Done with ISO3:OMN\n",
      "Done with ISO3:TUV\n",
      "Done with ISO3:ALA\n",
      "Done with ISO3:BRN\n",
      "Done with ISO3:TUN\n",
      "Done with ISO3:RUS\n",
      "Done with ISO3:BRB\n",
      "Done with ISO3:BRA\n",
      "Done with ISO3:CIV\n",
      "Done with ISO3:SRB\n",
      "Done with ISO3:GNQ\n",
      "Done with ISO3:USA\n",
      "Done with ISO3:QAT\n",
      "Done with ISO3:WSM\n",
      "Done with ISO3:AZE\n",
      "Done with ISO3:GNB\n",
      "Done with ISO3:SWZ\n",
      "Done with ISO3:TON\n",
      "Done with ISO3:CAN\n",
      "Done with ISO3:UKR\n",
      "Done with ISO3:KOR\n",
      "Done with ISO3:AIA\n",
      "Done with ISO3:CAF\n",
      "Done with ISO3:CHE\n",
      "Done with ISO3:CYP\n",
      "Done with ISO3:BIH\n",
      "Done with ISO3:SGP\n",
      "Done with ISO3:SGS\n",
      "Done with ISO3:SOM\n",
      "Done with ISO3:UZB\n",
      "Done with ISO3:CMR\n",
      "Done with ISO3:POL\n",
      "Done with ISO3:KWT\n",
      "Done with ISO3:ERI\n",
      "Done with ISO3:GAB\n",
      "Done with ISO3:CYM\n",
      "Done with ISO3:ARE\n",
      "Done with ISO3:EST\n",
      "Done with ISO3:MWI\n",
      "Done with ISO3:ESP\n",
      "Done with ISO3:IRQ\n",
      "Done with ISO3:SLV\n",
      "Done with ISO3:MLI\n",
      "Done with ISO3:IRL\n",
      "Done with ISO3:IRN\n",
      "Done with ISO3:ABW\n",
      "Done with ISO3:SLE\n",
      "Done with ISO3:PAN\n",
      "Done with ISO3:SDN\n",
      "Done with ISO3:SLB\n",
      "Done with ISO3:NZL\n",
      "Done with ISO3:MCO\n",
      "Done with ISO3:ITA\n",
      "Done with ISO3:JPN\n",
      "Done with ISO3:KGZ\n",
      "Done with ISO3:UGA\n",
      "Done with ISO3:NCL\n",
      "Done with ISO3:PNG\n",
      "Done with ISO3:ARG\n",
      "Done with ISO3:SWE\n",
      "Done with ISO3:BHS\n",
      "Done with ISO3:BHR\n",
      "Done with ISO3:ARM\n",
      "Done with ISO3:NRU\n",
      "Done with ISO3:CUB\n"
     ]
    }
   ],
   "source": [
    "appended_data=[]\n",
    "for k in cc_dict:\n",
    "    df_country = emudat2df(k)\n",
    "    appended_data.append(df_country)\n",
    "    print \"Done with ISO3:\"+k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "complete_df = pd.concat(appended_data, axis=0)\n",
    "complete_df.to_csv(\"CompleteListEMDAT.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dis_subtype       object\n",
       "dis_type          object\n",
       "end_date          object\n",
       "insur_dam         object\n",
       "iso               object\n",
       "location          object\n",
       "st_date           object\n",
       "total_affected    object\n",
       "total_dam         object\n",
       "total_deaths      object\n",
       "dtype: object"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = complete_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'to_numeric'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-105-7abc7ff22761>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numeric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/matthewschmitt/.virtualenvs/_web/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2358\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2359\u001b[0m             raise AttributeError(\"'%s' object has no attribute '%s'\" %\n\u001b[0;32m-> 2360\u001b[0;31m                                  (type(self).__name__, name))\n\u001b[0m\u001b[1;32m   2361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'to_numeric'"
     ]
    }
   ],
   "source": [
    "df = df.convert_objects(convert_numeric=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dis_subtype</th>\n",
       "      <th>dis_type</th>\n",
       "      <th>end_date</th>\n",
       "      <th>insur_dam</th>\n",
       "      <th>iso</th>\n",
       "      <th>location</th>\n",
       "      <th>st_date</th>\n",
       "      <th>total_affected</th>\n",
       "      <th>total_dam</th>\n",
       "      <th>total_deaths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1910-0005</th>\n",
       "      <td>Ground movement</td>\n",
       "      <td>Earthquake</td>\n",
       "      <td>24/06/1910</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DZA</td>\n",
       "      <td>Kabylie</td>\n",
       "      <td>24/06/1910</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1927-0012</th>\n",
       "      <td>--</td>\n",
       "      <td>Flood</td>\n",
       "      <td>01/11/1927</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DZA</td>\n",
       "      <td>Mostaganem</td>\n",
       "      <td>01/11/1927</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1946-0001</th>\n",
       "      <td>Ground movement</td>\n",
       "      <td>Earthquake</td>\n",
       "      <td>12/02/1946</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DZA</td>\n",
       "      <td>Constantine</td>\n",
       "      <td>12/02/1946</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1952-0026</th>\n",
       "      <td>--</td>\n",
       "      <td>Flood</td>\n",
       "      <td>/09/1952</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DZA</td>\n",
       "      <td></td>\n",
       "      <td>/09/1952</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1954-0017</th>\n",
       "      <td>Ground movement</td>\n",
       "      <td>Earthquake</td>\n",
       "      <td>09/09/1954</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DZA</td>\n",
       "      <td>Orleansville</td>\n",
       "      <td>09/09/1954</td>\n",
       "      <td>129250</td>\n",
       "      <td>6000</td>\n",
       "      <td>1250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               dis_subtype    dis_type    end_date  insur_dam  iso  \\\n",
       "1910-0005  Ground movement  Earthquake  24/06/1910        NaN  DZA   \n",
       "1927-0012               --       Flood  01/11/1927        NaN  DZA   \n",
       "1946-0001  Ground movement  Earthquake  12/02/1946        NaN  DZA   \n",
       "1952-0026               --       Flood    /09/1952        NaN  DZA   \n",
       "1954-0017  Ground movement  Earthquake  09/09/1954        NaN  DZA   \n",
       "\n",
       "               location     st_date  total_affected  total_dam  total_deaths  \n",
       "1910-0005       Kabylie  24/06/1910             NaN        NaN            12  \n",
       "1927-0012    Mostaganem  01/11/1927             NaN        NaN          3000  \n",
       "1946-0001   Constantine  12/02/1946             NaN        NaN           276  \n",
       "1952-0026                  /09/1952             NaN        NaN            25  \n",
       "1954-0017  Orleansville  09/09/1954          129250       6000          1250  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12128"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.to_pickle(\"complete_emdat_nat_haz.pkl\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'associated_dis': u'--',\n",
       " u'associated_dis2': u'--',\n",
       " u'country_name': u'United States',\n",
       " u'dis_subtype': u'Tropical cyclone',\n",
       " u'dis_type': u'Storm',\n",
       " u'disaster_no': u'1900-0003',\n",
       " u'end_date': u'08/09/1900',\n",
       " u'insur_dam': u'0',\n",
       " u'iso': u'USA',\n",
       " u'location': u'Galveston (Texas)',\n",
       " u'start_date': u'08/09/1900',\n",
       " u'total_affected': u'0',\n",
       " u'total_dam': u'30000',\n",
       " u'total_deaths': u'6000'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = data['data'][0]\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dis_subtype</th>\n",
       "      <th>dis_type</th>\n",
       "      <th>end_date</th>\n",
       "      <th>insur_dam</th>\n",
       "      <th>iso</th>\n",
       "      <th>location</th>\n",
       "      <th>st_date</th>\n",
       "      <th>total_affected</th>\n",
       "      <th>total_dam</th>\n",
       "      <th>total_deaths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1900-0003</th>\n",
       "      <td>Tropical cyclone</td>\n",
       "      <td>Storm</td>\n",
       "      <td>08/09/1900</td>\n",
       "      <td>0</td>\n",
       "      <td>USA</td>\n",
       "      <td>Galveston (Texas)</td>\n",
       "      <td>08/09/1900</td>\n",
       "      <td>0</td>\n",
       "      <td>30000</td>\n",
       "      <td>6000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1903-0002</th>\n",
       "      <td>--</td>\n",
       "      <td>Flood</td>\n",
       "      <td>//1903</td>\n",
       "      <td>0</td>\n",
       "      <td>USA</td>\n",
       "      <td>Passaic, Delaware</td>\n",
       "      <td>//1903</td>\n",
       "      <td>0</td>\n",
       "      <td>480000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1903-0003</th>\n",
       "      <td>--</td>\n",
       "      <td>Flood</td>\n",
       "      <td>//1903</td>\n",
       "      <td>0</td>\n",
       "      <td>USA</td>\n",
       "      <td>Heppner, Oregon</td>\n",
       "      <td>//1903</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1903-0010</th>\n",
       "      <td>Convective storm</td>\n",
       "      <td>Storm</td>\n",
       "      <td>//1903</td>\n",
       "      <td>0</td>\n",
       "      <td>USA</td>\n",
       "      <td>Gainesville (Georgia)</td>\n",
       "      <td>//1903</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1906-0004</th>\n",
       "      <td>Tropical cyclone</td>\n",
       "      <td>Storm</td>\n",
       "      <td>//1906</td>\n",
       "      <td>0</td>\n",
       "      <td>USA</td>\n",
       "      <td>Florida</td>\n",
       "      <td>//1906</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                dis_subtype dis_type    end_date insur_dam  iso  \\\n",
       "1900-0003  Tropical cyclone    Storm  08/09/1900         0  USA   \n",
       "1903-0002                --    Flood      //1903         0  USA   \n",
       "1903-0003                --    Flood      //1903         0  USA   \n",
       "1903-0010  Convective storm    Storm      //1903         0  USA   \n",
       "1906-0004  Tropical cyclone    Storm      //1906         0  USA   \n",
       "\n",
       "                        location     st_date total_affected total_dam  \\\n",
       "1900-0003      Galveston (Texas)  08/09/1900              0     30000   \n",
       "1903-0002      Passaic, Delaware      //1903              0    480000   \n",
       "1903-0003        Heppner, Oregon      //1903              0         0   \n",
       "1903-0010  Gainesville (Georgia)      //1903              0         0   \n",
       "1906-0004                Florida      //1906              0         0   \n",
       "\n",
       "          total_deaths  \n",
       "1900-0003         6000  \n",
       "1903-0002            0  \n",
       "1903-0003          250  \n",
       "1903-0010           98  \n",
       "1906-0004          164  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disaster_df = pd.DataFrame.from_dict(output).T\n",
    "disaster_df\n",
    "disaster_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dis_subtype       object\n",
       "dis_type          object\n",
       "end_date          object\n",
       "insur_dam         object\n",
       "iso               object\n",
       "location          object\n",
       "st_date           object\n",
       "total_affected    object\n",
       "total_dam         object\n",
       "total_deaths      object\n",
       "dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disaster_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1900-0003                                    Galveston (Texas)\n",
       "1903-0002                                    Passaic, Delaware\n",
       "1903-0003                                      Heppner, Oregon\n",
       "1903-0010                                Gainesville (Georgia)\n",
       "1906-0004                                              Florida\n",
       "1906-0005                      Mississippi, Alabama, Pensacola\n",
       "1906-0013                           San Francisco (California)\n",
       "1909-0003                                Grand Isle (Lousiana)\n",
       "1909-0004                                      Velasco (Texas)\n",
       "1909-0017                                            Louisiana\n",
       "1910-0003                                              Florida\n",
       "1913-0005                                 Ohio, Indiana, Texas\n",
       "1915-0004                                            El Centro\n",
       "1915-0005           Cavelston (Texas), New Orleans (Louisiana)\n",
       "1918-0003                                Louisiana (Southwest)\n",
       "1918-0007                                  Minnesota Wisconsin\n",
       "1918-0008                                         Mona Passage\n",
       "1919-0002                            Florida Keys, South Texas\n",
       "1920-0016                                 Alabama, Mississippi\n",
       "1925-0001                           Montana, Indiana, Illinois\n",
       "1925-0005                           Santa Barbara (California)\n",
       "1926-0003                                            Louisiana\n",
       "1926-0011                          Florida, Alabama, Pensacola\n",
       "1927-0005                             Greensville, Mississippi\n",
       "1927-0010                                    Tornado, St-Louis\n",
       "1928-0014                            Lake Okeechobee (Florida)\n",
       "1932-0002                                     Freeport (Texas)\n",
       "1932-0014                       Texas, Alabama, South Carolina\n",
       "1933-0004                                          South Texas\n",
       "1933-0007                              Long Beach (California)\n",
       "                                   ...                        \n",
       "2014-0048    New Jersey, New York states; Midwest, Plains, ...\n",
       "2014-0052    Midwest; Ohio Valley; New England; Northeast; ...\n",
       "2014-0053    Georgoa, Alabama, Mississipi, Louisiana, North...\n",
       "2014-0072    Washington DC, New York, Georgia, South Caroli...\n",
       "2014-0095                                   Oso (near Seattle)\n",
       "2014-0100    California, Plains, Midwest, Tenneessee Valley...\n",
       "2014-0126    Plains, Mississippi, Southeast, Midwest, Flori...\n",
       "2014-0165    Texas Panhandle (Hutchinson County), Southern ...\n",
       "2014-0192    Midwest, Plains, Rockies, Mid-Atlantic, Northe...\n",
       "2014-0263    Plains, Midwest, Ohio Valley, Mid-Atlantic, No...\n",
       "2014-0310                                               Hawaii\n",
       "2014-0317    Midwest, Northeast, Mid-Atlantic; Michigan, Ma...\n",
       "2014-0318    San Francisco Bay, Napa Valley, Northern Calif...\n",
       "2014-0444    Arkansas, Louisiana, Alabama, Mississippi, Ken...\n",
       "2014-0459    New York, New Hampshire, Michigan, Buffalo region\n",
       "2014-0482          Los Angeles, San Diego( California); Oregon\n",
       "2014-0491    Organge county, Yoosemite region, Los Angeles,...\n",
       "2014-0540    Blair (Nebraska); Iowa, Kansas, Arkansas, Wyoming\n",
       "2014-0553    South Dakota, Nebraska, Colorado, Minnesota, I...\n",
       "2014-9023                      San Joaquin valley (California)\n",
       "2015-0025                    Illinois, Wisconsin, Pennsylvania\n",
       "2015-0026    Connecticut; Maine; Massachusetts; New Hampshi...\n",
       "2015-0046             Tennessee, Kansas, Washington DC; Boston\n",
       "2015-0072                                   Illinois, Michigan\n",
       "2015-0122    Midwest, Mid-Atlantic, NorthEast, SouthWest, R...\n",
       "2015-0138                        Fairdale, Rochelle (Illinois)\n",
       "2015-0177    Nashville (Arkansas); Van (Texas); Delmond (So...\n",
       "2015-0180             Kansas, Nebraska, Texas, Oklahoma states\n",
       "2015-0186    San Marcos Municipality (Texas); Claremore (Ok...\n",
       "2015-0212                            Texas, Oklahoma, Colorado\n",
       "Name: location, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disaster_df.location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The original script I ran...\n",
    "```python\n",
    "def emudat2df(countryiso):\n",
    "    complete_dict.setdefault(countryiso, [])\n",
    "    url='http://www.emdat.be/disaster_list/php/search.php?_dc=1455563990858&continent=&region=&iso='+countryiso+'&from=1900&to=2015&group=Climatological%27%2C%27Geophysical%27%2C%27Hydrological%27%2C%27Meteorological&type=&options=associated_dis%2Cassociated_dis2%2Ctotal_deaths%2Ctotal_affected%2Ctotal_dam%2Cinsur_dam&page=1&start=0&limit=25'\n",
    "    response = urllib2.urlopen(url)\n",
    "    data = json.load(response)\n",
    "    output = {}\n",
    "    count = int (len(data['data']) - 1)\n",
    "    while count >= 0:\n",
    "        adisaster = data['data'][count]['disaster_no']\n",
    "        dis_type = data['data'][count]['dis_type']\n",
    "        dis_subtype = data['data'][count]['dis_subtype']\n",
    "        st_date = data['data'][count]['start_date']\n",
    "        end_date = data['data'][count]['end_date']\n",
    "        iso = data['data'][count]['iso']\n",
    "        location = data['data'][count]['location']\n",
    "        total_affected = data['data'][count]['total_affected']\n",
    "        total_dam = data['data'][count]['total_dam']\n",
    "        total_deaths = data['data'][count]['total_deaths']\n",
    "        insur_dam = data['data'][count]['insur_dam']\n",
    "        adis = {\n",
    "            \"iso\": iso,\n",
    "            \"location\": location,\n",
    "            \"dis_type\": dis_type,\n",
    "            \"dis_subtype\": dis_subtype,\n",
    "            \"st_date\": st_date,\n",
    "            \"end_date\": end_date,\n",
    "            \"total_affected\": total_affected,\n",
    "            \"total_dam\": total_dam,\n",
    "            \"total_deaths\": total_deaths,\n",
    "            \"insur_dam\": insur_dam\n",
    "        }\n",
    "        output[adisaster] = adis\n",
    "        count = count - 1\n",
    "    complete_dict[countryiso] = output\n",
    "    df = pd.DataFrame.from_dict(output).T\n",
    "    return df\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sources Cited\n",
    "\n",
    "[ref1]: http://fabio-lana.blogspot.it/2015/07/using-python-for-mixing-hystorical-data.html \"Fabios Blog\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
